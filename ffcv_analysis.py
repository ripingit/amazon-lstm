#analyzes the vectors generated by doc2vec using a feed-forward neural network

import IPython
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dropout, Dense, Activation
from keras.layers.normalization import BatchNormalization

#usecols=range(0,150)
#x_train_vectors = open("x_train_vectors.txt", "r", encoding = "utf-8")
#x_test_vectors = open("x_test_vectors.txt", "r", encoding = "utf-8")

x_train = np.load("x_train_cv.npy").item()
x_test  = np.load("x_test_cv.npy").item()
y_train = np.load("y_train_cv.npy")
y_test  = np.load("y_test_cv.npy")



#the actual model
model = Sequential()

model.add(Dense(64, input_dim = 32900, activation = 'relu'))
model.add(Dropout(0.5))
#model.add(BatchNormalization())
model.add(Dense(64, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])

model.fit(x_train, y_train, epochs=4, validation_split = 0.5, batch_size=128)

score = model.evaluate(x_test, y_test, batch_size = 128)

print(score)

IPython.embed()